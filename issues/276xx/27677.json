{
   "active_lock_reason" : null,
   "assignee" : null,
   "assignees" : [],
   "author_association" : "MEMBER",
   "body" : "@sipa and I gave a presentation to some other developers recently about some work we've been doing to redesign how the mempool works, and I wanted to share a writeup outlining our thoughts with a broader audience to further the discussion.  I've also attached a PDF of slides that go along with this: [Reinventing the Mempool.pdf](https://github.com/bitcoin/bitcoin/files/11490409/Reinventing.the.Mempool.pdf).\r\n\r\n--------\r\n\r\n# Summary\r\n\r\nThe current mempool is primarily designed around maintaining two different sort orders, where for each transaction we keep track of its position in an ancestor-feerate-sort and in a descendant-feerate-sort.  We then use those two cached sort orders in order to implement eviction and mining.\r\n\r\nThose algorithms are deficient in several ways. In particular, the eviction algorithm does not guarantee that the first transaction evicted would be the last transaction mined, and there exist situations where we could evict a transaction that would otherwise actually be mined in the next block.\r\n\r\nFurthermore, the mining algorithm is more complex than the ancestor feerate sort we maintain, and it is insufficient to merely do lookups into our ancestor feerate index to determine which of two transactions will be mined from the mempool first. This lack of a total ordering on mempool transactions makes RBF calculations difficult to align with miner incentives, and creates distortions where we sometimes can replace transactions via RBF that would actually be better for a miner than the replacement.\r\n\r\nTo solve all these problems, we propose maintaining a total ordering on mempool transactions, which we use to implement a mining and eviction algorithm that are symmetrically opposite and provide better RBF rules for determining when to allow a replacement to occur.\r\n\r\n# Background\r\n\r\n## Eviction and mining are not opposite\r\n\r\nSometimes our eviction criteria might remove something that would be mined in the next block from our mempool. Consider:\r\n\r\n```mermaid\r\ngraph TD;\r\n    A[Tx A: size 250, fee 250]-->B;\r\n    A-->C;\r\n    A-->E[Tx E: size 250, fee 49750];\r\n    B[Tx B: size 50000, fee 50000]-->D[Tx D: size 500, fee 52000];\r\n    C[Tx C: size 50000, fee 50000]-->D;\r\n```\r\n\r\nNote that the ancestor feerate of E is 100 sat/byte, while the descendant feerate of A is 2 sat/byte.  In particular, the descendant feerate of A is lowest among all transactions in this diagram, so if it were also the lowest descendant feerate package in the mempool, then we might evict A, and therefore E, even though (A, E) might otherwise be selected for the next block.\r\n\r\n## RBF is not incentive compatible\r\n\r\nThere are many forms of incentive incompatibility baked into the BIP 125 replacement rules:\r\n * The \"no-new-parents\" rule doesn't consider the replacement transaction's desirability to a miner -- it might be better than all the to-be-replaced transactions, despite the new unconfirmed parent.\r\n * The rule requiring that a new transaction pays a higher feerate than its direct conflicts is insufficient to ensure that the new transaction is more desirable than what is being evicted. One of the direct conflicts could have a smaller set of unconfirmed parents than the new transaction, resulting in a higher ancestor feerate. Moreover, because we don't compare feerates of any indirect conflicts -- that is, descendants of direct conflicts -- with the feerate of the new transaction, it's possible that we're evicting a child transaction that would otherwise be mined in the next block with something that will not be mined for a long time.\r\n\r\nSee https://github.com/bitcoin/bitcoin/pull/26451 for more discussion of the second point.\r\n\r\n# Proposed solution\r\n\r\nIf we're able to maintain a total ordering on the mempool, then we can design efficient algorithms that will solve these problems.\r\n\r\n## How to maintain a total ordering\r\n\r\nWith the current algorithm and rules, it is infeasible to continuously maintain a fully-ordered mempool at all times. Ordering an $n$-transaction mempool from scratch scales with $O(d n \\log n)$, where $d$ is the descendant limit (default 25), which quickly becomes too much when the mempool grows beyond a trivial size. And unfortunately, doing this incrementally (just re-ordering affected transactions whenever updates happen) does not help, because even a single added transaction can change the ordering of all remaining ones.\r\n\r\nAs an example of this effect, consider the following transaction graph (ancestor feerates of children are in parentheses):\r\n\r\n```mermaid\r\ngraph TD;\r\n    A[Tx A: size 1000, fee 1000]-->D[\"Tx D: size 1000, fee 19000 (10 s/b)\"];\r\n    A-->E[\"Tx E: size 1000, fee 35000 (7.47 s/b)\"];\r\n    B[Tx B: size 3250, fee 3250]-->E;\r\n    B-->F[\"Tx F: size 1000, fee 77500 (6.36 s/b)\"];\r\n    C[Tx C: size 10000, fee 10000]-->F;\r\n```\r\n\r\nWith these ancestor feerates, Tx D should be included first along with its parent Tx A. Once Tx A is included, Tx E sees its ancestor feerate go up, and it is included next with its parent, and so on to produce the ordering: [A, D, B, E, C, F].\r\n\r\nNow consider a single transaction being added, Tx G:\r\n\r\n```mermaid\r\ngraph TD;\r\n    A[Tx A: size 1000, fee 1000]-->D[\"Tx D: size 1000, fee 19000 (10 s/b)\"];\r\n    A-->E[\"Tx E: size 1000, fee 35000 (7.47 s/b)\"];\r\n    B[Tx B: size 3250, fee 3250]-->E;\r\n    B-->F[\"Tx F: size 1000, fee 77500 (6.36 s/b)\"];\r\n    C[Tx C: size 10000, fee 10000]-->F;\r\n    C-->G[\"Tx G: size 1000, fee 210000 (20 s/b)\"]\r\n```\r\n\r\nTransaction G now has the highest ancestor feerate, and so it would be chosen first in our ancestor-feerate-based ordering. Once Tx G and its parent Tx C are included, Tx F will see its ancestor feerate increase as it only has one remaining ancestor to consider. It will rise to have the highest ancestor feerate of all remaining transactions, and so it will be the next transaction included, along with its parent Tx B. Once Tx B is in, Tx E has the next highest ancestor feerate and we can see that the final ordering of transactions is: [C, G, B, F, A, E, D]. Note that the order in which the child transactions appear has been reversed, and moreover, the number of transactions in this graph could be extended arbitrarily while retaining this behavior.\r\n\r\nFundamentally this means that we need to bound the number of transactions whose ordering can be affected by individual changes to the mempool. Our main insight is that this number is exactly the size of the largest \"cluster\" of transactions that we might have in the mempool, where a \"cluster\" is a set of transactions that are connected via ancestor/descendant relationships in the transaction graph.\r\n\r\nOur proposal is thus to introduce a limit on the size of clusters in the mempool. It then becomes feasible to maintain an ordering for all the individual clusters at all times, and perform a quick merge sort over all of them whenever a total ordering of the entire mempool is needed.\r\n\r\n### Definitions\r\n\r\n#### Linearizations\r\n\r\nWe introduce the term \"linearization\" to refer to any topologically valid ordering of transactions. This could be an ancestor-feerate-based ordering of transactions (like we use in the mining code today), or it could be the optimal ordering (one where we choose amongst all possible subsets of transactions the topologically valid subset that maximizes feerate, and repeat until all transactions are selected).  Or it could be something in between; for the purposes of discussion we abstract away the details of the cluster ordering algorithm, or \"linearization\", that we might settle on.\r\n\r\n#### Chunks\r\n\r\nOur intuition for cluster linearization algorithms is that we often will choose transactions with lower feerate before we choose transactions with higher feerate, because of topology constraints. This is a consequence of behaviors like \"child- pays-for-parent\".  So when thinking about how we might compare transactions from two different clusters to determine which  one is \"better\" (eg for mining) or \"worse\" (eg for eviction), we don't just want to look at the first or last transaction in the cluster. Instead, our intuition is that we want to look at the same package of transactions that our ordering algorithm would have used in coming up with the ordering in the first place.\r\n\r\nThis concept, that transactions should be looked at in some aggregate with other transactions, can be generalized in a way that is indifferent to the underlying linearization algorithm that is used. For a given linearized cluster  $[tx_1, ..., tx_n]$, we can partition the cluster into a series of disjoint \"chunks\" $[c_1, c_2, ..., c_j]$ where $c_1 = [tx_1, ..., tx_{i_1}]$, $c_2 = [tx_{i_1+1}, ..., tx_{i_2}]$ ,..., $c_j = [tx_{i_{j-1}+1}, ..., tx_n]$, such that the feerate of each chunk is no greater than the feerate of the chunk that precedes it. \r\n\r\nAnother way of putting it: chunks are the partitioning of a cluster that respects the linearization in a way that ensures that feerates from one chunk to the next are monotonically decreasing.\r\n\r\nGiven any cluster linearization, it turns out that it's possible to construct the chunks for the cluster in linear time, and this operation is independent of the linearization algorithm that may have been used.\r\n\r\n### Implementing fundamental mempool operations\r\n\r\nFor the sake of discussion below, let's now imagine that our mempool is grouped into its different clusters, and each cluster is linearized using some algorithm (perhaps the ancestor-feerate-based mining algorithm in use today, or perhaps an optimal ordering), and those linearized clusters are each chunked into their monotonically decreasing feerate order.  Given such a mempool, we can design algorithms to implement the fundamental mempool operations.\r\n\r\n#### Mining\r\n\r\nOur goal with mining is to maximize the fees in a block template, and we do so by applying a greedy algorithm. \r\n\r\n1. Make a feerate-sorted heap consisting of the first chunk from each cluster (these will be the highest feerate chunks), sorted by highest-feerate.\r\n2. Remove the top of the heap and add to the block candidate.\r\n3. If the cluster from which the selection was made has more chunks left, insert the next best chunk from that cluster into the heap.\r\n4. Continue removing chunks from the heap until the block is full.\r\n\r\nNote that when we approach the end of a block, we run into a knapsack problem where chunks may not fit. How we might optimize the end of a block is deferred for later discussion.\r\n\r\n#### Eviction\r\n\r\nOur goal with eviction is to remove the transactions that would be the last ones selected by our mining algorithm. With a  fully ordered mempool, this calculation is straightforward and mirrors the mining algorithm.\r\n\r\n1. Make a heap consisting of the last chunk from each cluster (these will be the lowest feerate chunks), ordered by lowest feerate.\r\n2. Remove the top of the heap and evict from the mempool.\r\n3. If the cluster from which the selection was made has more chunks left, insert the next lowest feerate chunk from that cluster into the heap.\r\n4. Continue removing chunks from the heap and evicting until the mempool's memory limit is satisfied.\r\n\r\nAs with our current eviction algorithm, we will also bump up the mempool's minimum fee to be an increment above the highest feerate chunk that was evicted.\r\n\r\n#### RBF\r\n\r\nOur goal with RBF is to allow \"better\" transactions (those that will benefit a miner to take) than some existing, conflicting transactions in a way that is resistant to DoS but is otherwise as permissible as practical.\r\n\r\nGiven a mempool where all clusters are ordered and chunked, we can assign a score to a transaction which is the chunk feerate of the chunk to which it belongs.  Then our main RBF incentive compatibility rule just becomes:\r\n\r\n1. A replacement transaction must have a chunk feerate greater than that of all transactions which it would evict.\r\n\r\nThis would eliminate the BIP 125 rule against replacements introducing new unconfirmed parents and replaces the BIP 125 feerate rule in which a replacement transaction must have a higher individual feerate than all direct conflicts.\r\n\r\nHowever, at least for now, we would retain some of the additional anti-DoS rules:\r\n\r\n1. A replacement transaction must pay more total fees than the sum of fees paid by all evicted transactions.\r\n2. A replacement transaction must not evict more than (100?) existing transactions.\r\n\r\nThe first of those rules prevents free-relay attacks, while some version of the second rule is necessary to prevent us from needing to re-cluster/re-order too much of the mempool while processing a single transaction.\r\n\r\n## Some open questions\r\n\r\n1. Philosophically, is it problematic for RBF rules to be even more of a \"black box\" than the BIP 125 algorithm?\r\n2. Are there usage patterns for wallets or other protocols that would be fundamentally harmed by cluster size limits? Do we know what values would be acceptable or what values would be insufficient?\r\n3. What can we do if a high feerate transaction arrives that would violate the cluster limit? Can we design some sort of \"cluster-sibling eviction\" algorithm that is DoS-resistant and would help reduce the downsides of cluster size limits?\r\n4. Is it problematic if linearization algorithms used on the network are non-deterministic?\r\n   * We could imagine using a variety of linearization algorithms at any given moment -- perhaps for small clusters we use an exponential run-time optimal ordering algorithm, while for medium sized clusters we do something different, like an ancestor-feerate-based ordering, or an optimal ordering with some bounded computation limits.\r\n   * Are there situations where different nodes having different orders causes meaningful user-facing issues with transactions not relaying effectively, eg because of the use of chunk feerates in the RBF algorithm?\r\n5. Chunk sizes should be bounded in vbytes, so that we don't exacerbate the knapsack problem during mining. However, what is the best way to do that?\r\n   * We could just bound the vbytes allowed in a single cluster, which would guarantee that chunks are not too big.\r\n   * Or we could design linearization algorithms and adapt our chunking logic to never produce chunks bigger than a certain size -- but this would come at the expense of chunks within a cluster no longer having monotonically decreasing feerates. This may be possible to do, but is the need for large clusters (measured in vbytes) great enough to warrant the complexity that this would introduce in our algorithms?\r\n\r\n# Current status and next steps\r\n\r\n1. First draft implementation of this logic is done (link to be added).\r\n2. Analyzing effects of this logic on historical transaction data is in process, to try to answer questions like:\r\n   * How big are the clusters we've historically seen / what is the cluster size distribution on the network today\r\n   * How would the network have been affected if we'd had cluster sizes bounded at various different values in the past\r\n3. Performance analysis of all the mempool operations (particularly as a function of cluster size) to ensure that mempool operations are optimized with this approach.\r\n4. The information gathered will (eventually) inform a concrete proposal for what cluster size limits we might consider (along with chunk vbyte and/or cluster vbyte limits).\r\n",
   "closed_at" : null,
   "closed_by" : null,
   "comments" : 1,
   "comments_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/27677/comments",
   "created_at" : "2023-05-16T17:29:33Z",
   "events_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/27677/events",
   "html_url" : "https://github.com/bitcoin/bitcoin/issues/27677",
   "id" : 1712437859,
   "labels" : [],
   "labels_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/27677/labels{/name}",
   "locked" : false,
   "milestone" : null,
   "node_id" : "I_kwDOABII585mEbpj",
   "number" : 27677,
   "performed_via_github_app" : null,
   "reactions" : {
      "+1" : 7,
      "-1" : 0,
      "confused" : 0,
      "eyes" : 1,
      "heart" : 0,
      "hooray" : 0,
      "laugh" : 0,
      "rocket" : 0,
      "total_count" : 8,
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/27677/reactions"
   },
   "repository_url" : "https://api.github.com/repos/bitcoin/bitcoin",
   "state" : "open",
   "state_reason" : null,
   "timeline_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/27677/timeline",
   "title" : "Proposal for a new mempool design",
   "updated_at" : "2023-05-17T09:26:34Z",
   "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/27677",
   "user" : {
      "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
      "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
      "followers_url" : "https://api.github.com/users/sdaftuar/followers",
      "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
      "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
      "gravatar_id" : "",
      "html_url" : "https://github.com/sdaftuar",
      "id" : 7463573,
      "login" : "sdaftuar",
      "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
      "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
      "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
      "repos_url" : "https://api.github.com/users/sdaftuar/repos",
      "site_admin" : false,
      "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
      "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
      "type" : "User",
      "url" : "https://api.github.com/users/sdaftuar"
   }
}
